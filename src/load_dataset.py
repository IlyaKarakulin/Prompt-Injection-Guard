from datasets import load_dataset


def explore_dataset(train_path, test_path, format="parquet"):
    dataset = get_dataset(train_path, test_path, format)
    
    print("üìä –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –¥–∞—Ç–∞—Å–µ—Ç–µ:")
    print(f"–†–∞–∑–º–µ—Ä —Ç—Ä–µ–Ω–∏—Ä–æ–≤–æ—á–Ω–æ–π –≤—ã–±–æ—Ä–∫–∏: {len(dataset['train']):,} –ø—Ä–∏–º–µ—Ä–æ–≤")
    print(f"–†–∞–∑–º–µ—Ä —Ç–µ—Å—Ç–æ–≤–æ–π –≤—ã–±–æ—Ä–∫–∏: {len(dataset['test']):,} –ø—Ä–∏–º–µ—Ä–æ–≤")
    
    train_labels = dataset['train']['label']
    test_labels = dataset['test']['label']
    
    print(f"\nüè∑Ô∏è –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –º–µ—Ç–æ–∫ –≤ —Ç—Ä–µ–Ω–∏—Ä–æ–≤–æ—á–Ω–æ–π –≤—ã–±–æ—Ä–∫–µ:")
    print(f"–ò–Ω—ä–µ–∫—Ü–∏–∏ (1): {sum(train_labels):,}")
    print(f"–ù–æ—Ä–º–∞–ª—å–Ω—ã–µ (0): {len(train_labels) - sum(train_labels):,}")
    
    print(f"\nüè∑Ô∏è –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –º–µ—Ç–æ–∫ –≤ —Ç–µ—Å—Ç–æ–≤–æ–π –≤—ã–±–æ—Ä–∫–µ:")
    print(f"–ò–Ω—ä–µ–∫—Ü–∏–∏ (1): {sum(test_labels):,}")
    print(f"–ù–æ—Ä–º–∞–ª—å–Ω—ã–µ (0): {len(test_labels) - sum(test_labels):,}")
    
    print("\nüîç –ü—Ä–∏–º–µ—Ä—ã –∏–Ω—ä–µ–∫—Ü–∏–π:")
    injection_examples = [ex for ex in dataset['train'] if ex['label'] == 1][:3]
    for i, ex in enumerate(injection_examples):
        print(f"{i+1}. {ex['text'][:200]}...")
    
    print("\nüîç –ü—Ä–∏–º–µ—Ä—ã –Ω–æ—Ä–º–∞–ª—å–Ω—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤:")
    normal_examples = [ex for ex in dataset['train'] if ex['label'] == 0][:3]
    for i, ex in enumerate(normal_examples):
        print(f"{i+1}. {ex['text'][:200]}...")
    
    return dataset


def get_dataset(train_path, test_path, format="parquet"):
    dataset = load_dataset(format, data_files={
        'train': train_path,
        'test': test_path
    })
    
    return dataset